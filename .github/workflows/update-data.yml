name: Update data

on:
  schedule:
    # Runs frequently on match days
    - cron: '*/5 12-23 * * SAT,SUN'
    - cron: '*/5 19-23 * * MON-FRI'
    # Runs once daily for a full refresh
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-generate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python Dependencies
        run: pip install beautifulsoup4 requests

      - name: Load Configuration Variables
        id: load_config
        run: |
          if [[ -f "./config.env" ]]; then
            source ./config.env
            echo "TEAM_NAME=${TEAM_SLUG}" >> $GITHUB_ENV
            echo "LEAGUE_ID_NAME=${LEAGUE_ID_NAME}" >> $GITHUB_ENV
            # Pass the multi-line config as an environment variable
            echo "LEAGUE_CONFIG<<EOF" >> $GITHUB_ENV
            echo "${LEAGUE_CONFIG}" >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          else
            echo "‚ùå ERROR: config.env file not found."
            exit 1
          fi

      - name: Run Python Scraper and EPG Generator
        env:
          TEAM_NAME: ${{ env.TEAM_NAME }}
          LEAGUE_ID_NAME: ${{ env.LEAGUE_ID_NAME }}
          LEAGUE_CONFIG: ${{ env.LEAGUE_CONFIG }}
        shell: python
        run: |
          import os
          import json
          import requests
          from bs4 import BeautifulSoup
          from datetime import datetime, timedelta, timezone

          # --- CONFIGURATION ---
          TEAM_NAME = os.environ.get('TEAM_NAME', '').replace('-', ' ')
          LEAGUE_ID_NAME = os.environ.get('LEAGUE_ID_NAME')
          LEAGUE_CONFIG_RAW = os.environ.get('LEAGUE_CONFIG', '')
          HEADERS = {'User-Agent': 'Mozilla/5.0'}
          
          # Parse the multi-line LEAGUE_CONFIG into a list of dicts
          LEAGUES = []
          for line in LEAGUE_CONFIG_RAW.strip().split('\n'):
              if ',' in line:
                  slug, urn = line.strip().split(',')
                  LEAGUES.append({'slug': slug, 'urn': urn})

          # --- DATA FETCHING ---
          def fetch_json(url):
              try:
                  print(f"Fetching JSON: {url}")
                  r = requests.get(url, headers=HEADERS)
                  r.raise_for_status()
                  return r.json()
              except Exception as e:
                  print(f"‚ùå Error fetching JSON: {e}")
                  return None

          def fetch_html(url):
              try:
                  print(f"Fetching HTML: {url}")
                  r = requests.get(url, headers=HEADERS)
                  r.raise_for_status()
                  return r.text
              except Exception as e:
                  print(f"‚ùå Error fetching HTML: {e}")
                  return None

          # --- PARSING ---
          def parse_standings(html_content):
              if not html_content: return []
              soup = BeautifulSoup(html_content, 'html.parser')
              table = soup.find('table', {'data-testid': 'football-table'})
              if not table: return []
              standings_data = []
              # ... (rest of function is unchanged)
              return standings_data # This is a placeholder, the full function is below

          # --- EPG GENERATION ---
          def create_epg(all_teams, all_fixtures):
              now_utc = datetime.now(timezone.utc)
              future_limit = now_utc + timedelta(days=60) # Furthest time for "No Game" block
              
              xml = '<?xml version="1.0" encoding="UTF-8"?>\n<tv>'
              
              team_fixtures = {team: [] for team in all_teams}
              for fix in all_fixtures:
                  team_fixtures.setdefault(fix['home_team'], []).append(fix)
                  team_fixtures.setdefault(fix['away_team'], []).append(fix)

              for team_name in sorted(all_teams):
                  team_slug = ''.join(c for c in team_name.lower().replace('&', 'and').replace(' ', '-') if c.isalnum() or c == '-')
                  xml += f'\n  <channel id="{team_slug}.uk"><display-name lang="en">{team_name}</display-name></channel>'

                  # Sort this team's fixtures by date
                  sorted_fixtures = sorted(team_fixtures.get(team_name, []), key=lambda x: x['datetime_utc'])
                  
                  next_game_start = None
                  if sorted_fixtures:
                      next_game_start = datetime.fromisoformat(sorted_fixtures[0]['datetime_utc'].replace('Z', '+00:00'))

                  # Create the "No Game" block
                  stop_time = next_game_start if next_game_start else future_limit
                  if stop_time > now_utc:
                      start_str = now_utc.strftime('%Y%m%d%H%M%S %z')
                      stop_str = stop_time.strftime('%Y%m%d%H%M%S %z')
                      xml += f'\n  <programme start="{start_str}" stop="{stop_str}" channel="{team_slug}.uk">'
                      xml += f'<title lang="en">No Game Scheduled</title></programme>'

                  # Create all the actual game programmes
                  for fixture in sorted_fixtures:
                      home_team, away_team = fixture['home_team'], fixture['away_team']
                      is_home_game = team_name == home_team
                      opponent = away_team if is_home_game else home_team
                      venue = "(H)" if is_home_game else "(A)"
                      
                      dt_start = datetime.fromisoformat(fixture['datetime_utc'].replace('Z', '+00:00'))
                      dt_stop = dt_start + timedelta(hours=2)
                      start_str, stop_str = dt_start.strftime('%Y%m%d%H%M%S %z'), dt_stop.strftime('%Y%m%d%H%M%S %z')
                      
                      xml += f'\n  <programme start="{start_str}" stop="{stop_str}" channel="{team_slug}.uk">'
                      xml += f'<title lang="en">vs. {opponent} {venue}</title><desc lang="en">{fixture.get("competition", LEAGUE_ID_NAME)}</desc><category lang="en">Sports</category></programme>'

              xml += '\n</tv>'
              with open('epg.xml', 'w', encoding='utf-8') as f: f.write(xml)
              print("‚úÖ EPG file generated successfully.")

          # --- MAIN EXECUTION ---
          def main():
              all_standings = []
              all_fixtures = []
              all_teams = set()

              for league in LEAGUES:
                  print(f"\n--- Processing {league['slug']} ---")
                  # 1. Fetch standings
                  standings_url = f"https://www.bbc.co.uk/sport/football/{league['slug']}/table"
                  standings_html = fetch_html(standings_url)
                  current_standings = parse_standings(standings_html)
                  all_standings.extend(current_standings)
                  for team in current_standings:
                      all_teams.add(team['team']['name'])

                  # 2. Fetch fixtures from the API
                  today = datetime.now()
                  end_date = today + timedelta(days=60)
                  fixtures_api_url = f"https://www.bbc.co.uk/sport/football/--schedules/public/v1/programmes?start={today.strftime('%Y-%m-%d')}&end={end_date.strftime('%Y-%m-%d')}&urn={league['urn']}"
                  
                  fixtures_json = fetch_json(fixtures_api_url)
                  if fixtures_json:
                      for programme in fixtures_json.get('programmes', []):
                          if programme.get('state') == 'pre':
                              all_fixtures.append({
                                  'home_team': programme['homeTeam']['name']['full'],
                                  'away_team': programme['awayTeam']['name']['full'],
                                  'datetime_utc': programme['startTime'],
                                  'competition': programme['tournament']['name']['full']
                              })
              
              print(f"‚úÖ Parsed {len(all_fixtures)} total fixture details from BBC API.")

              # 3. Create 'Next Up' map
              next_up_map = {}
              # First sort by date to find the *actual* next game
              sorted_fixtures = sorted(all_fixtures, key=lambda x: x['datetime_utc'])
              for fix in sorted_fixtures:
                  if fix['home_team'] not in next_up_map: next_up_map[fix['home_team']] = f"{fix['away_team']} (H)"
                  if fix['away_team'] not in next_up_map: next_up_map[fix['away_team']] = f"{fix['home_team']} (A)"
              
              for team in all_standings:
                  if team['team']['name'] in next_up_map:
                      team['nextUp'] = next_up_map[team['team']['name']]
              
              # 4. Save output files
              os.makedirs('data', exist_ok=True)
              with open('data/standings.json', 'w') as f:
                  json.dump({'response': [{'league': {'name': LEAGUE_ID_NAME, 'standings': [all_standings]}}]}, f, indent=4)
              with open('data/fixtures.json', 'w') as f:
                  json.dump(all_fixtures, f, indent=4)

              # 5. Generate the EPG
              create_epg(all_teams, all_fixtures)

              print("üöÄ Scrape and EPG generation complete.")

          # Re-insert the full parse_standings function here
          def parse_standings(html_content):
              if not html_content: return []
              soup = BeautifulSoup(html_content, 'html.parser')
              table = soup.find('table', {'data-testid': 'football-table'})
              if not table: return []
              standings_data = []
              tbody = table.find('tbody')
              if not tbody: return []
              for row in tbody.find_all('tr'):
                  cells = row.find_all(['th', 'td'])
                  if len(cells) < 10: continue
                  try:
                      team_name_span = cells[0].find('span', class_='visually-hidden')
                      team_name = team_name_span.get_text(strip=True) if team_name_span else "Unknown"
                      standings_data.append({
                          'rank': int(cells[0].find('span', class_=lambda c: c and 'Rank' in c).get_text(strip=True)),
                          'team': {'name': team_name, 'logo': cells[0].find('img')['src'] if cells[0].find('img') else ''},
                          'points': int(cells[8].get_text(strip=True)),
                          'goalsDiff': int(cells[7].get_text(strip=True)),
                          'form': "".join([div.get_text(strip=True) for div in cells[9].find_all('div', {'data-testid': 'letter-content'})]),
                          'all': {
                              'played': int(cells[1].get_text(strip=True)), 'win': int(cells[2].get_text(strip=True)),
                              'draw': int(cells[3].get_text(strip=True)), 'lose': int(cells[4].get_text(strip=True)),
                              'goals': {'for': int(cells[5].get_text(strip=True)), 'against': int(cells[6].get_text(strip=True))}
                          },
                          'highlight': True if TEAM_NAME and TEAM_NAME in team_name.lower() else False, 'nextUp': 'TBD'
                      })
                  except: continue
              # This print statement is now inside the main loop, so we can remove it here.
              return standings_data
              
          if __name__ == "__main__":
              main()
      
      - name: Commit and Push Data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/standings.json data/fixtures.json epg.xml
          if git diff --staged --quiet; then
            echo "üü¢ No data changes to commit."
          else
            git commit -m "üìä Automated standings and EPG update"
            git push
          fi
