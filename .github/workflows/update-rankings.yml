name: Update Rankings

on:
  schedule:
    - cron: '0 0 * * *' # every day at midnight
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-rank:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Install Python Dependencies
        run: pip install beautifulsoup4

      - name: Load Configuration Variables
        id: load_config
        run: |
          if [[ -f "./config.env" ]]; then
            echo "Loading variables from config.env"
            source ./config.env
            echo "TEAM_NAME=$TEAM_NAME" >> $GITHUB_ENV
            echo "LEAGUE_URL=$LEAGUE_URL" >> $GITHUB_ENV
            echo "FIXTURES_URL=$FIXTURES_URL" >> $GITHUB_ENV
            echo "SEASON=$SEASON" >> $GITHUB_ENV
            echo "LEAGUE_ID_NAME=$LEAGUE_ID_NAME" >> $GITHUB_ENV
          else
            echo "‚ùå ERROR: config.env file not found. Please create it."
            exit 1
          fi

      - name: Fetch and Parse Standings Table (Robust Script Execution)
        run: |
          mkdir -p data tmp
          
          # 1. Fetch the HTML content
          echo "Fetching HTML standings from $LEAGUE_URL"
          curl -s -A "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" "$LEAGUE_URL" -o tmp/bbc-standings.html
          
          # 2. Write Python script to a file
          cat <<'PYTHON_SCRIPT' > tmp/scrape.py
import json
from bs4 import BeautifulSoup
import sys
import os

LEAGUE_ID_NAME = os.environ.get('LEAGUE_ID_NAME', 'League')
SEASON = os.environ.get('SEASON', 'Unknown')

try:
    with open('tmp/bbc-standings.html', 'r', encoding='utf-8') as f:
        html_content = f.read()
except FileNotFoundError:
    print('Error: Could not read tmp/bbc-standings.html')
    sys.exit(1)

soup = BeautifulSoup(html_content, 'html.parser')

# --- CRITICAL: Find the main standings table ---
standings_table = soup.find('table', class_=lambda c: c and 'table' in c.lower() and 'ssrcss' in c)

if not standings_table:
    print('Error: Could not find the main standings table (check BBC class names).')
    # Write debug information to a file
    with open('tmp/debug_html_start.txt', 'w') as dbg:
        dbg.write("HTML CONTENT START\\n")
        dbg.write(html_content[:4000]) 
    print('A debug file tmp/debug_html_start.txt was created to inspect the fetched content. Check your logs.')
    sys.exit(1)

data_list = []
tbody = standings_table.find('tbody')

if not tbody:
    print('Error: Table body not found.')
    sys.exit(1)
    
for row in tbody.find_all('tr'):
    cols = row.find_all(['th', 'td'])
    
    if len(cols) < 10:
        continue 

    try:
        rank_text = cols[0].get_text(strip=True)
        # Extract Team Name
        team_name_element = cols[1].find('span', class_='ssrcss-1c9v1s-Name') 
        team_name = team_name_element.get_text(strip=True) if team_name_element else cols[1].get_text(strip=True)
        
        team_data = {
            'rank': int(rank_text),
            'team_name': team_name,
            'played': int(cols[2].get_text(strip=True)),
            'won': int(cols[3].get_text(strip=True)),
            'drawn': int(cols[4].get_text(strip=True)),
            'lost': int(cols[5].get_text(strip=True)),
            'goals_for': int(cols[6].get_text(strip=True)),
            'goals_against': int(cols[7].get_text(strip=True)),
            'goal_difference': int(cols[8].get_text(strip=True)),
            'points': int(cols[9].get_text(strip=True)),
        }
        data_list.append(team_data)
        
    except Exception as e:
        print(f'Skipping row due to parsing error: {e}')
        continue

final_json = {
    'league_info': {
        'name': LEAGUE_ID_NAME,
        'season': SEASON
    },
    'standings': data_list
}

with open('data/standings.json', 'w') as outfile:
    json.dump(final_json, outfile, indent=4)
    
print('‚úÖ Standings JSON generated successfully: data/standings.json')
PYTHON_SCRIPT
          
          # 3. Execute the script file
          python3 tmp/scrape.py
          
      - name: Fetch Upcoming Fixtures (HTML)
        run: |
          mkdir -p public/cal
          echo "Fetching fixtures from $FIXTURES_URL"
          curl -s -A "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" "$FIXTURES_URL" -o public/cal/fixtures.html
          echo "Future ICS calendar source saved as public/cal/fixtures.html"

      - name: Generate League Info File
        run: |
          echo "{\"league_id\": \"$LEAGUE_ID_NAME\", \"season\": \"$SEASON\"}" > data/league-info.json

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"
          git add data/league-info.json data/standings.json public/cal/fixtures.html
          if git diff --cached --quiet; then
            echo "üü¢ No changes to commit."
          else
            git commit -m "Scrape update: Standings and fixtures from BBC Sport for $LEAGUE_ID_NAME"
            git push
          fi
